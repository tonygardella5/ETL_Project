{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Project\n",
    "* Data Source 2 - API\n",
    "* Source :  Spaceflight News\n",
    "* Website:  https://spaceflightnewsapi.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"docs\": [],\n",
      "    \"hasNextPage\": false,\n",
      "    \"hasPrevPage\": false,\n",
      "    \"limit\": 10,\n",
      "    \"nextPage\": null,\n",
      "    \"page\": 1,\n",
      "    \"pagingCounter\": 1,\n",
      "    \"prevPage\": null,\n",
      "    \"totalDocs\": 0,\n",
      "    \"totalPages\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://spaceflightnewsapi.net/api/v1/articles?page=1/articles?spacex'\n",
    "#page = 4\n",
    "\n",
    "#url = f'https://spaceflightnewsapi.net/api/v1/articles? + 'page'{page} + /articles?spacex'\n",
    "\n",
    "# Pretty print JSON for all SpaceX news\n",
    "response = requests.get(url).json()\n",
    "print(json.dumps(response, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# URL for GET requests to retrieve SpaceX news\n",
    "url = \"https://spaceflightnewsapi.net/api/v1/articles?search=spacex\"\n",
    "\n",
    "# Pretty print JSON for all SpaceX news\n",
    "response = requests.get(url).json()\n",
    "print(json.dumps(response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store responses\n",
    "json_responses = []\n",
    "\n",
    "#Loop through all responses\n",
    "for x in range (20):\n",
    "    r = requests.get(url).json()\n",
    "    json_responses.append(r) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_responses)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for specific data\n",
    "title = []\n",
    "published_date = []\n",
    "featured_image = []\n",
    "launches = []\n",
    "news_sites = []\n",
    "url = []\n",
    "\n",
    "\n",
    "# Loop through all the responses and append lists\n",
    "for i in response['docs']:\n",
    "    title.append(i['title'])\n",
    "    published_date.append(i[\"published_date\"])\n",
    "    featured_image.append(i[\"featured_image\"])\n",
    "    launches.append(i[\"launches\"])\n",
    "    news_sites.append(i[\"news_site\"])\n",
    "    url.append(i[\"url\"])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop data\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame out of appended lists\n",
    "df = pd.DataFrame({\"Title\": title,\n",
    "                 \"Published Date\": published_date,\n",
    "                  \"Featured Image\": featured_image,\n",
    "                  \"Launches\": launches,\n",
    "                  \"News Sites\": news_sites,\n",
    "                  \"URL\": url})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Published Date type from object to datetime\n",
    "df[\"Published Date\"] = pd.to_datetime(df[\"Published Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Published Date data types\n",
    "df[\"Published Date\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date in ascending order\n",
    "df = df.sort_values([\"Published Date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to csv file\n",
    "df.to_csv(\"../Resources/news_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as json for database entry\n",
    "df.to_json(\"../Resources/news_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Open SpaceX_df\n",
    "spacex_file = \"../Resources/SpaceX_info.csv\"\n",
    "spacex_df = pd.read_csv(spacex_file)\n",
    "spacex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df, spacex_df])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as json for database entry\n",
    "#merged_df.to_json(\"../Resources/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as sql\n",
    "#merged_df.to_sql(name=\"SpaceX\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default port used by MongoDB is 27017\n",
    "# https://docs.mongodb.com/manual/reference/default-mongodb-port/\n",
    "#conn = 'mongodb://localhost:27017'\n",
    "#client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Declare the database\n",
    "#db = client.spacex_db\n",
    "\n",
    "# Declare the collection\n",
    "#spacex = db.spacex_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the document into the database\n",
    "# The database and collection, if they don't already exist, will be created at this point.\n",
    "#spacex.insert_one(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(f'postgresql://postgres:postgres@localhost:5432/employee_db')\n",
    "connection = engine.connect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python38532bitcb40cf36389f42b9a883d6f9fe55ee79"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
